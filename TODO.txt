Notes:

With replacing NaNs: 0.00646
Without replacing NaNs: 0.00577
My guess: null hypothesis (i.e. no difference)

Validation:

- check that submissions do not have duplicate entries for a given user

- Maybe visualize items using t-SNE?
	http://blog.applied.ai/visualising-high-dimensional-data/

Questions:

- is purchased list a subset of visited list?
	No it isn't. This needs further investigation.
- how does the distribution of #purchased compare with the distribution of #visited?
	Visitations are larger as expected.


TODO:

1.
	Take feature vectors of user-item combinations. Response classes: purchased, visited, not viewed, visited but not purchased, etc. Use a powerful classifier with regularization.
 
	This will result in ~100,000,000 records. Probably enough to deal with the high dimensionality.
 
	http://ac.els-cdn.com.ezproxy.library.ubc.ca/S095741741500038X/1-s2.0-S095741741500038X-main.pdf?_tid=56f59ed4-58c4-11e5-beb1-00000aab0f02&acdnat=1442003780_d5090dd1f92c125b82923d018685d31c
 
	Transforming collaborative filtering into supervised learning â€“ may need UBC library to get access.

2. look at netflix prize solution: http://blog.echen.me/2011/10/24/winning-the-netflix-prize-a-summary/

3. Create separate Models in code for:
	- purchased coupon model
	- visited coupon model
	- similar users' coupons model
	- user behaviour model (activity level of user, etc.)
	- coupon behaviour model (popularity of coupon, etc.)
	Then, use model averaging along with compare_MAP function in R to build an ensemble.

4. Calculate Coverage metric for model (Item space and User space coverage)





	
